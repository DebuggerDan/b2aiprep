{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from b2aiprep.dataset import VBAIDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reformatted the data into a [BIDS](https://bids-standard.github.io/bids-starter-kit/folders_and_files/folders.html)-like format. The data is stored in a directory with the following structure:\n",
    "\n",
    "```\n",
    "data/\n",
    "    sub-01/\n",
    "        ses-01/\n",
    "            beh/\n",
    "                sub-01_ses-01_questionnaire.json\n",
    "    sub-02/\n",
    "        ses-01/\n",
    "            beh/\n",
    "                sub-01_ses-01_questionnaire.json\n",
    "    ...\n",
    "```\n",
    "\n",
    "i.e. the data reflects a subject-session-datatype hierarchy. The `beh` subfolder, for behavioural data, was chosen to store questionnaire data as it is the closest approximation to the data collected.\n",
    "\n",
    "We have provided utilities which load in data from the BIDS-like dataset structure. The only input needed is the folder path which stores the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: allow user to specify input folder input\n",
    "dataset = VBAIDataset('../output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every user has a sessionschema which we can get info for the users from\n",
    "qs = dataset.load_questionnaires('sessionschema')\n",
    "q_dfs = []\n",
    "for subject_id, questionnaire in qs.items():\n",
    "    # get the dataframe for this questionnaire\n",
    "    df = dataset.questionnaire_to_dataframe(questionnaire)\n",
    "    q_dfs.append(df)\n",
    "\n",
    "# concatenate all the dataframes\n",
    "sessionschema_df = pd.concat(q_dfs)\n",
    "sessionschema_df = pd.pivot(sessionschema_df, index='record_id', columns='linkId', values='valueString')\n",
    "sessionschema_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above process involves: (1) finding all the questionnaire files for a specific named questionnaire, (2) loading in the data from the JSON files, and (3) concatenating the data into a single dataframe. For convenience, the `load_and_pivot_questionnaire` helper function automatically performs these tasks for a given questionnaire. Let's try it with the demographics dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = dataset.load_and_pivot_questionnaire('demographics')\n",
    "demographics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate through a couple of columns and summarize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['children', 'country', 'ethnicity', 'gender_identity', 'grandparent', 'housing_status']:\n",
    "    print(demographics_df[column].value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants dataframe\n",
    "\n",
    "We can get a dataframe summarizing the participants in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df = dataset.load_and_pivot_questionnaire('participant')\n",
    "participant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar chart of participant by enrollment institution\n",
    "plt.figure(figsize=(10, 5))\n",
    "participant_df['enrollment_institution'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session data\n",
    "\n",
    "Load in the `QuestionnaireResponse` objects for the session schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_schema = dataset.load_questionnaires('sessionschema')\n",
    "# show the first item\n",
    "record_id = list(session_schema.keys())[0]\n",
    "\n",
    "# Each element is a QuestionnaireResponse, a pydantic object\n",
    "# you can serialize it to a python dictionary with .dict()\n",
    "# and to a json with .json()\n",
    "# otherwise attributes are accessible like any other python object\n",
    "print(session_schema[record_id].json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function which loads in the above as a dataframe\n",
    "session_df = dataset.load_and_pivot_questionnaire('sessionschema')\n",
    "session_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at a specific questionnaire which is collected for each session in a similar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_confounders = dataset.load_questionnaires('confounders')\n",
    "# show the first item\n",
    "record_id = list(session_confounders.keys())[0]\n",
    "\n",
    "# Each element is a QuestionnaireResponse, a pydantic object\n",
    "# you can serialize it to a python dictionary with .dict()\n",
    "# and to a json with .json()\n",
    "# otherwise attributes are accessible like any other python object\n",
    "print(session_confounders[record_id].json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acoustic tasks\n",
    "\n",
    "Let's look at the acoustic tasks now. Acoustic task files are organized in the following way:\n",
    "\n",
    "```\n",
    "data/\n",
    "    sub-01/\n",
    "        ses-01/\n",
    "            beh/\n",
    "                sub-01_ses-01_task-<TaskName>_acoustictaskschema.json\n",
    "                sub-01_ses-01_task-<TaskName>_rec-<TaskName>-1_recordingschema.json\n",
    "                ...\n",
    "```\n",
    "\n",
    "where `TaskName` is the name of the acoustic task, including:\n",
    "\n",
    "* `Audio-Check`\n",
    "* `Cinderalla-Story`\n",
    "* `Rainbow-Passage`\n",
    "\n",
    "etc. The audio tasks are listed currently in b2aiprep/prepare.py:_AUDIO_TASKS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_tasks = dataset.load_questionnaires('acoustictaskschema')\n",
    "acoustic_tasks\n",
    "# show the first item\n",
    "record_id = list(acoustic_tasks.keys())[0]\n",
    "print(acoustic_tasks[record_id].json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the above corresponds to a different acoustic task: an audio check, prolonged vowels, etc. The `value_counts()` method for pandas DataFrames lets us count all the unique values for a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_tasks_df = dataset.load_and_pivot_questionnaire('acoustictaskschema')\n",
    "acoustic_tasks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above will list out all of the acoustic tasks, as every acoustic task is associated with a single \"acoustictaskschema\" `QuestionnaireResponse` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_tasks_df['acoustic_task_name'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b2ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
